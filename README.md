# ðŸ¤Ÿ Real-Time Sign Language Recognition System

This project uses **deep learning** and **computer vision** to recognize American Sign Language (ASL) alphabets in real time through a webcam. It combines a **CNN model trained on ASL images** with **MediaPipe hand tracking** and **OpenCV visualization** to create an interactive and accurate gesture recognition system.

---

## ðŸš€ Features

- Real-time hand gesture detection using webcam
- ASL alphabet classification using trained CNN model
- Top-3 predictions with confidence scores on screen
- Hand landmark visualization using MediaPipe
- Dataset augmentation for improved model robustness

---
## ðŸ§° Technologies Used

### ðŸ§  Machine Learning / Deep Learning
- **TensorFlow** + **Keras** â€“ Designing and training the CNN model
- **ImageDataGenerator** â€“ For on-the-fly image augmentation during training
- **NumPy** â€“ Efficient numerical operations and image array manipulation

### ðŸ“¸ Computer Vision
- **OpenCV** â€“ Capturing webcam feed and rendering real-time hand visualizations
- **MediaPipe** â€“ Real-time hand landmark detection from video frames

### ðŸ“Š Evaluation & Visualization
- **scikit-learn** â€“ Evaluation metrics like confusion matrix, classification report, ROC AUC
- **matplotlib** â€“ Plotting confusion matrix, ROC curve, and saving sample predictions






