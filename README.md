# ðŸ¤Ÿ Real-Time Sign Language Recognition System

This project uses **deep learning** and **computer vision** to recognize American Sign Language (ASL) alphabets in real time through a webcam. It combines a **CNN model trained on ASL images** with **MediaPipe hand tracking** and **OpenCV visualization** to create an interactive and accurate gesture recognition system.

---

## ðŸš€ Features

- Real-time hand gesture detection using webcam
- ASL alphabet classification using trained CNN model
- Top-3 predictions with confidence scores on screen
- Hand landmark visualization using MediaPipe
- Dataset augmentation for improved model robustness

---
## ðŸ§° Technologies Used

### ðŸ§  Machine Learning / Deep Learning
- **TensorFlow** + **Keras** â€“ Designing and training the CNN model
- **ImageDataGenerator** â€“ For on-the-fly image augmentation during training
- **NumPy** â€“ Efficient numerical operations and image array manipulation

### ðŸ“¸ Computer Vision
- **OpenCV** â€“ Capturing webcam feed and rendering real-time hand visualizations
- **MediaPipe** â€“ Real-time hand landmark detection from video frames

### ðŸ“Š Evaluation & Visualization
- **scikit-learn** â€“ Evaluation metrics like confusion matrix, classification report, ROC AUC
- **matplotlib** â€“ Plotting confusion matrix, ROC curve, and saving sample predictions

### ðŸ§ª Testing & Analysis
- **ConfusionMatrixDisplay** â€“ Visual representation of class-wise prediction accuracy
- **ROC AUC Score / Curve** â€“ Measures multi-class classifier performance
- **Classification Report** â€“ Detailed precision, recall, f1-score for each sign class
- **label_binarize** â€“ For multi-class ROC AUC scoring

### ðŸ’» Development Environment
- **Python (3.7+)**
- **Virtual Environment (venv)** â€“ Isolated package management for clean setup
- **OS** â€“ Windows (tested); cross-platform compatible




